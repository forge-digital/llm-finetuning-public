{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is for testing and getting familiar with embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a sentence transformer embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aappopulkkinen/repos/llm-finetuning-public/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/aappopulkkinen/repos/llm-finetuning-public/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: DistilBertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder = SentenceTransformer(\"msmarco-distilbert-base-v4\")\n",
    "embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the above embedder has first a transformer layer and then a pooling layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.37452352e-01, -4.49766785e-01,  5.94369173e-01, -3.64690214e-01,\n",
       "       -2.04791799e-01,  9.67684269e-01,  4.59626615e-01,  1.13824344e+00,\n",
       "        6.86243951e-01, -1.44724578e-01, -8.19937170e-01, -2.27527738e-01,\n",
       "       -5.06509781e-01, -2.50946224e-01,  7.02426910e-01, -4.33130145e-01,\n",
       "        1.50074840e-01,  2.91990250e-01, -2.18762130e-01, -5.76998889e-01,\n",
       "       -5.91868639e-01,  9.97827768e-01,  7.48944819e-01, -1.04504779e-01,\n",
       "        1.31007805e-01, -1.01986721e-01,  3.01252782e-01, -8.44390094e-01,\n",
       "       -1.92844257e-01, -2.89206877e-02, -3.71905029e-01,  5.61008334e-01,\n",
       "       -8.65827739e-01,  7.32985139e-01,  7.27419078e-01,  9.89027470e-02,\n",
       "       -1.00309134e-01, -1.09461918e-01,  1.47822231e-01,  1.59677878e-01,\n",
       "        5.94619989e-01,  1.25826165e-01,  1.18856937e-01,  3.86250794e-01,\n",
       "        4.10713792e-01, -2.79500365e-01,  2.73893446e-01,  6.11875176e-01,\n",
       "        1.18775442e-01,  2.80967146e-01,  4.16664451e-01, -2.86158681e-01,\n",
       "        1.87005639e-01,  5.59037685e-01, -1.37824744e-01, -5.54888546e-01,\n",
       "       -3.87310356e-01, -2.84073532e-01,  1.94272339e-01,  1.89014561e-02,\n",
       "       -1.57379001e-01,  2.85569161e-01,  7.68845975e-02, -7.82679021e-02,\n",
       "        7.14976862e-02, -4.94476557e-01,  8.13197672e-01,  4.09667969e-01,\n",
       "        5.90765059e-01, -1.33993077e+00, -7.03009740e-02,  7.53422439e-01,\n",
       "       -4.00141299e-01, -9.11751449e-01, -2.58342147e-01, -4.41665709e-01,\n",
       "       -8.71174689e-03,  5.17127514e-01, -1.51168332e-01, -1.01742089e-01,\n",
       "        9.32402909e-01,  8.45559478e-01, -1.55144641e-02,  1.21993802e-01,\n",
       "        2.98034608e-01,  2.76875526e-01, -2.55837291e-01, -4.11726266e-01,\n",
       "        5.59924804e-02,  6.54723525e-01,  8.04976746e-02, -2.15760022e-01,\n",
       "       -2.44208634e-01,  2.40944162e-01, -2.66486079e-01, -4.58311081e-01,\n",
       "       -1.43445939e-01,  4.99340259e-02, -4.00774002e-01, -1.01426280e+00,\n",
       "       -2.28639647e-01,  1.80756271e-01,  4.59449559e-01, -6.09229267e-01,\n",
       "        9.82484758e-01,  1.52214810e-01, -5.47319017e-02, -3.14948171e-01,\n",
       "        5.14023662e-01, -1.12559430e-01,  4.08231854e-01,  3.98372442e-01,\n",
       "        9.77009237e-01,  4.74437058e-01,  3.27785611e-01,  4.55660850e-01,\n",
       "       -6.60520941e-02, -7.50670612e-01, -2.25257188e-01,  2.16821939e-01,\n",
       "        4.36812490e-02,  1.63131326e-01,  3.37914884e-01, -1.42658323e-01,\n",
       "        3.32828462e-01, -3.12231630e-01, -2.04189181e-01, -2.27419123e-01,\n",
       "       -4.77105319e-01, -9.74572718e-01,  4.70576108e-01,  1.16946679e-02,\n",
       "       -4.27912951e-01,  8.08423534e-02,  1.03374176e-01,  2.79278845e-01,\n",
       "        3.70991886e-01,  4.60027307e-01,  5.67662179e-01,  4.23459560e-01,\n",
       "        3.52933437e-01, -4.13821429e-01,  8.26459944e-01, -1.82479694e-01,\n",
       "       -3.94547582e-01,  8.22952747e-01,  5.74802339e-01, -3.29770356e-01,\n",
       "       -1.34931982e-01, -2.03176364e-01, -2.27325693e-01,  1.37071520e-01,\n",
       "        4.01863873e-01, -2.73239225e-01,  8.28379095e-02, -3.88185114e-01,\n",
       "        4.82381731e-01, -3.46366495e-01, -7.62794435e-01, -4.74332422e-01,\n",
       "       -8.23873699e-01, -1.28268972e-01,  1.19678760e+00,  3.54550064e-01,\n",
       "        3.21847200e-01, -3.48309547e-01,  4.17161614e-01, -4.56618369e-01,\n",
       "       -3.78436387e-01,  6.17761850e-01, -3.76007795e-01, -4.36660826e-01,\n",
       "        2.70981252e-01, -4.94064778e-01,  3.69618237e-01,  6.29163146e-01,\n",
       "       -2.49223247e-01, -1.89116076e-02,  3.84759724e-01,  2.38520667e-01,\n",
       "       -9.62983608e-01,  3.11985426e-02, -4.07888032e-02, -3.11620265e-01,\n",
       "       -3.87207806e-01, -1.78888485e-01, -2.43620172e-01,  1.46521792e-01,\n",
       "       -5.79480290e-01, -1.70463130e-01,  1.93192706e-01, -4.91737425e-01,\n",
       "        2.25609884e-01,  2.51217723e-01, -2.62250125e-01, -7.36418307e-01,\n",
       "       -4.82995689e-01, -5.56915820e-01, -3.09793577e-02, -1.72040582e-01,\n",
       "       -7.84726381e-01,  1.12349913e-01,  5.76122403e-01,  5.24183959e-02,\n",
       "        3.75717044e-01,  3.41964304e-01, -8.07157576e-01, -4.85477418e-01,\n",
       "        1.31088108e-01,  1.25500545e-01,  7.09762812e-01, -2.70091861e-01,\n",
       "        9.06565115e-02, -1.72317982e-01, -4.40067291e-01, -1.86328396e-01,\n",
       "       -6.97808713e-02,  7.14047849e-02,  1.15111686e-01,  1.37963653e-01,\n",
       "       -4.36523646e-01,  3.26684028e-01,  1.00562930e+00, -9.28783268e-02,\n",
       "        4.41594869e-01, -2.80941308e-01, -2.50174552e-01,  4.44621772e-01,\n",
       "       -3.45868826e-01, -2.64309257e-01, -6.91614300e-02, -5.30216336e-01,\n",
       "       -2.92507619e-01,  7.46625960e-01, -6.41686916e-01,  6.23609088e-02,\n",
       "       -3.36758107e-01,  1.68863118e-01, -2.41260096e-01, -5.53506017e-01,\n",
       "        6.20213091e-01,  2.15499192e-01, -2.97378808e-01, -4.60838526e-01,\n",
       "       -3.83123904e-01, -2.17852265e-01,  7.31921077e-01,  1.78447217e-01,\n",
       "       -4.64140713e-01,  1.86968505e-01, -7.68512487e-01, -5.12847662e-01,\n",
       "       -6.40630126e-01, -5.36372304e-01,  1.00225925e-01, -5.98197103e-01,\n",
       "       -1.04904473e-01, -3.94384861e-02,  1.19579390e-01, -2.68723726e-01,\n",
       "       -2.88588971e-01, -6.56052172e-01,  2.09015813e-02,  1.38562366e-01,\n",
       "        5.08089401e-02, -2.38293827e-01, -8.47352564e-01, -7.90061951e-01,\n",
       "       -6.54291883e-02, -3.98708642e-01,  4.01414752e-01,  6.66013241e-01,\n",
       "       -3.57289076e-01,  4.49261904e-01, -3.97364609e-02,  1.17720447e-01,\n",
       "        5.37690043e-01,  5.44461071e-01, -2.61020422e-01,  4.63818878e-01,\n",
       "       -6.08555116e-02,  2.55984925e-02, -1.12500787e+00, -8.16098988e-01,\n",
       "        1.65052727e-01,  5.02767801e-01,  3.52619767e-01, -6.19356930e-01,\n",
       "       -3.37750465e-01, -3.96377891e-02,  8.28640401e-01,  3.06429118e-01,\n",
       "        8.75205849e-04, -5.02186358e-01,  3.47512275e-01, -6.39968663e-02,\n",
       "        1.36424914e-01,  1.09864092e+00, -5.34654438e-01,  2.04912871e-01,\n",
       "        1.10565342e-01, -3.80349070e-01,  5.06455183e-01,  2.56315649e-01,\n",
       "        1.07308209e+00, -5.11251986e-01,  1.37319699e-01,  4.03590828e-01,\n",
       "        6.81143045e-01, -6.90560564e-02, -4.41470742e-01,  8.65551770e-01,\n",
       "       -5.36489068e-03, -1.92063332e-01,  6.26882017e-01,  1.02954423e+00,\n",
       "        2.02916712e-01, -3.16348374e-01,  1.05325930e-01,  4.81094688e-01,\n",
       "        2.70651519e-01,  1.99400753e-01, -4.52258348e-01,  3.83000553e-01,\n",
       "        1.78242683e-01, -5.05904257e-02,  7.62886822e-01,  3.62530909e-02,\n",
       "       -5.86439192e-01, -2.66041517e-01,  5.11985064e-01,  6.18965030e-01,\n",
       "        3.33804905e-01, -1.14057887e+00, -6.26417041e-01,  2.87640840e-01,\n",
       "        1.42917144e+00, -7.48331964e-01, -1.70239061e-01, -4.69810277e-01,\n",
       "       -8.53147924e-01, -1.28478959e-01,  4.12095815e-01,  6.42256141e-01,\n",
       "        7.84825921e-01, -2.79156059e-01,  8.73275623e-02,  5.22443652e-03,\n",
       "       -1.24216013e-01,  1.18871234e-01,  5.58371127e-01,  5.95756650e-01,\n",
       "       -8.46817568e-02,  1.92907806e-02,  9.80805874e-01, -1.40289009e-01,\n",
       "       -5.43310523e-01,  5.68605900e-01, -2.98529804e-01,  3.71592104e-01,\n",
       "        1.48724869e-01, -4.37213182e-01,  4.49539959e-01, -3.76098067e-01,\n",
       "        3.91334534e-01,  7.40846574e-01, -6.18496835e-01, -2.93728262e-01,\n",
       "        7.22610131e-02, -4.08460110e-01, -1.10731453e-01, -6.22073412e-01,\n",
       "        2.73612123e-02,  2.41265506e-01, -8.95974874e-01,  1.78299397e-01,\n",
       "       -2.75831580e-01, -1.20159709e+00,  3.08812171e-01,  4.11383450e-01,\n",
       "       -1.28390741e+00, -8.04085210e-02,  7.98433647e-03,  1.13650471e-01,\n",
       "        9.97592211e-01,  2.42925584e-01,  4.15990829e-01,  4.76928204e-01,\n",
       "       -1.34936363e-01, -1.28000095e-01, -3.23377192e-01,  3.37980270e-01,\n",
       "        1.68964043e-01, -7.69583881e-02,  8.59455615e-02,  1.62751153e-01,\n",
       "       -7.37050474e-01, -2.47569174e-01, -5.65834582e-01, -7.16711223e-01,\n",
       "        7.81069472e-02, -3.12114805e-01, -6.56635642e-01,  1.39164895e-01,\n",
       "       -7.53256202e-01,  4.47383493e-01, -4.92980391e-01, -2.74638552e-02,\n",
       "        6.03107214e-01,  2.37349987e-01, -4.59446728e-01,  1.72519848e-01,\n",
       "       -3.86246949e-01,  6.40192628e-02,  6.65732026e-01,  9.14366782e-01,\n",
       "        4.62839872e-01,  2.86018014e-01,  3.27259272e-01, -5.23030832e-02,\n",
       "        4.31596309e-01, -5.55132190e-03, -1.41818509e-01,  5.60912311e-01,\n",
       "       -4.22254771e-01, -6.52837932e-01,  1.27253771e-01,  6.51569366e-01,\n",
       "       -8.75301600e-01,  4.10480231e-01, -5.12456074e-02,  1.60181180e-01,\n",
       "        2.24379539e-01, -2.86697507e-01, -1.71369836e-01, -7.37675250e-01,\n",
       "        3.17295581e-01, -4.08832967e-01,  5.95783114e-01, -4.09971684e-01,\n",
       "        3.94016802e-01, -2.66436845e-01,  6.42321110e-01,  4.32344407e-01,\n",
       "       -8.70747790e-02, -4.95006368e-02, -2.48799518e-01,  2.17487484e-01,\n",
       "       -2.10964680e-01,  5.22491813e-01,  6.00503922e-01,  3.07288229e-01,\n",
       "       -1.25274092e-01, -1.65217295e-01, -4.17960167e-01, -1.16941042e-01,\n",
       "       -6.43929839e-01, -3.25790018e-01,  8.90897214e-02,  4.15057898e-01,\n",
       "       -5.58568358e-01, -5.74885488e-01,  3.67792308e-01,  7.68045604e-01,\n",
       "        9.87520814e-02, -4.16083597e-02,  1.22739625e+00, -4.67738390e-01,\n",
       "        3.61277461e-01, -1.21259978e-02,  2.45835349e-01,  4.81719196e-01,\n",
       "        1.28695071e-01, -7.16342270e-01, -2.15989307e-01, -9.65597853e-02,\n",
       "        2.67169386e-01,  2.73533612e-01,  5.72187483e-01,  4.54979658e-01,\n",
       "       -1.11224018e-01, -8.91852155e-02, -2.13050455e-01,  1.64843686e-02,\n",
       "       -4.07078922e-01,  3.46446708e-02, -3.77919972e-01,  8.91237557e-02,\n",
       "        4.24709529e-01,  4.13704187e-01, -7.41744459e-01, -2.14394674e-01,\n",
       "       -5.95714092e-01,  7.32215494e-02,  1.57429680e-01,  7.08644748e-01,\n",
       "        5.56014776e-01,  5.21712244e-01,  2.22114976e-02,  8.89873922e-01,\n",
       "       -4.04604554e-01,  7.16723919e-01, -1.21457040e+00,  4.67971921e-01,\n",
       "       -2.81611830e-01, -4.22089845e-01, -3.74851495e-01,  7.42429914e-03,\n",
       "        5.31890512e-01, -1.68501735e-02,  2.23650128e-01, -2.30944410e-01,\n",
       "       -6.26726687e-01,  7.66278207e-01, -1.33106545e-01, -1.77397095e-02,\n",
       "        2.43754864e-01,  4.77316119e-02, -1.19542432e+00, -2.68696100e-01,\n",
       "       -1.08722574e-03,  5.85354745e-01, -1.00840306e+00,  3.19787040e-02,\n",
       "        8.65131259e-01, -1.18545204e-01, -1.70648806e-02, -4.33919907e-01,\n",
       "        2.31518783e-02,  2.18136460e-01,  1.57442503e-02,  7.33738113e-03,\n",
       "        8.60225707e-02, -5.92280030e-01,  2.53353536e-01,  3.39242309e-01,\n",
       "       -3.00930962e-02,  7.96026960e-02, -5.66729724e-01,  7.53105432e-02,\n",
       "        3.85042638e-01, -1.42399982e-01,  5.14973402e-01,  4.53352332e-01,\n",
       "       -7.93648660e-02, -6.36398435e-01, -3.04755867e-01,  8.52795765e-02,\n",
       "       -5.16288519e-01, -2.77459696e-02,  1.03538299e+00, -6.26419485e-01,\n",
       "       -3.67626071e-01,  2.54050255e-01,  3.80790919e-01, -6.94301873e-02,\n",
       "       -6.56946525e-02, -5.75541735e-01,  2.88217403e-02, -2.29518656e-02,\n",
       "        1.12087183e-01, -4.91206259e-01,  4.54724394e-02,  6.25762865e-02,\n",
       "       -4.05218266e-02, -2.99434870e-01,  1.69907033e-01,  3.61360945e-02,\n",
       "        3.45467806e-01, -1.55545533e+00, -7.22393468e-02, -4.07782912e-01,\n",
       "        4.60451782e-01, -1.67815000e-01,  8.42172801e-02,  3.64150226e-01,\n",
       "       -9.64034200e-01, -2.44192824e-01,  2.55658507e-01,  6.62348866e-01,\n",
       "        3.39194089e-02,  7.96378478e-02,  1.05368182e-01,  6.47190213e-01,\n",
       "        1.98827267e-01, -2.83925891e-01, -5.82891665e-02, -6.08273327e-01,\n",
       "       -2.45189622e-01,  5.28466582e-01,  4.25350577e-01,  1.69884562e-01,\n",
       "       -5.56793451e-01, -2.08425134e-01, -3.79673779e-01, -2.20816284e-01,\n",
       "       -5.57137549e-01, -6.97122395e-01,  3.48238111e-01, -2.29829755e-02,\n",
       "       -3.36473852e-01,  1.87880456e-01, -8.71589333e-02,  2.47902811e-01,\n",
       "       -1.92613244e-01, -1.31189287e-01,  1.26966143e+00, -5.70286691e-01,\n",
       "       -7.35839307e-01,  3.48349325e-02, -1.34490535e-01,  5.66207349e-01,\n",
       "        1.49747655e-01,  6.34891510e-01, -5.37689328e-01,  1.73656598e-01,\n",
       "        8.73860538e-01,  5.39494455e-01,  2.45232910e-01, -2.75809139e-01,\n",
       "        2.69037694e-01, -2.47813419e-01,  3.28995675e-01, -5.08033276e-01,\n",
       "       -1.36626288e-01, -5.25125206e-01,  6.38625175e-02,  1.60170719e-01,\n",
       "        5.25581479e-01, -5.42534702e-02, -5.78013897e-01, -2.93439806e-01,\n",
       "        7.36907840e-01,  8.96540284e-02, -2.78521836e-01,  5.48194408e-01,\n",
       "        2.60446459e-01,  2.85749882e-01,  3.08503777e-01,  4.91247118e-01,\n",
       "       -1.56283528e-01,  4.48864937e-01,  3.07384804e-02, -1.44857943e-01,\n",
       "       -4.34659749e-01, -1.18936494e-01,  3.03541839e-01,  2.76228935e-01,\n",
       "       -2.19053164e-01, -3.52867246e-01,  2.11204946e-01,  4.29378062e-01,\n",
       "       -3.32666010e-01, -3.40846747e-01, -3.09739739e-01, -9.21843350e-01,\n",
       "       -3.17131698e-01,  2.05157641e-02,  8.95967543e-01,  2.85350233e-02,\n",
       "       -3.06709975e-01, -5.18094540e-01, -2.03632742e-01, -4.30442214e-01,\n",
       "        8.93194973e-01,  1.88005313e-01, -8.19193065e-01, -8.01915452e-02,\n",
       "       -5.02968669e-01,  1.55695423e-01,  3.45096260e-01, -4.57636833e-01,\n",
       "        3.99608940e-01,  9.23501030e-02, -6.07730746e-01, -2.79775620e-01,\n",
       "       -2.19819069e-01,  2.94138701e-03,  5.83463460e-02,  5.39227188e-01,\n",
       "        1.17017543e-02,  6.60128891e-01,  9.05399978e-01, -1.04323852e+00,\n",
       "       -4.62149113e-01, -1.47834092e-01,  1.03358559e-01, -7.52374083e-02,\n",
       "       -7.19209850e-01, -7.49261916e-01,  7.72259176e-01,  3.57427806e-01,\n",
       "       -3.36479872e-01,  6.22364819e-01, -4.04982656e-01, -6.66124701e-01,\n",
       "       -5.50894812e-02,  9.90108177e-02, -1.32606030e-01, -5.33047795e-01,\n",
       "       -8.85037035e-02,  1.47773936e-01,  3.03712487e-01, -9.22756612e-01,\n",
       "       -2.76571333e-01,  6.58803225e-01, -5.87004647e-02, -2.89668858e-01,\n",
       "       -2.90722307e-02,  2.59593695e-01, -3.72257642e-02, -5.05316317e-01,\n",
       "        6.52269840e-01,  1.61018014e-01, -5.94720423e-01, -4.40109909e-01,\n",
       "        3.06165040e-01,  3.74075800e-01,  6.85525179e-01, -1.13456368e+00,\n",
       "        9.04812992e-01, -1.45968720e-01,  1.38529003e-01, -1.80918261e-01,\n",
       "        2.90195704e-01, -1.60478070e-01,  2.41768867e-01,  7.34725177e-01,\n",
       "        2.48813480e-01, -5.27789474e-01, -8.68307829e-01, -3.11723173e-01,\n",
       "       -2.77221382e-01,  2.82270331e-02,  1.06772475e-01,  6.69835448e-01,\n",
       "       -7.36287534e-01,  8.00877690e-01, -7.77732849e-01, -6.94176614e-01,\n",
       "       -2.93087065e-01,  3.10118884e-01, -4.15873170e-01,  3.83180350e-01,\n",
       "       -8.40328872e-01,  9.81774926e-03, -1.52766556e-01, -2.00992972e-01,\n",
       "       -1.07778811e+00, -9.17742103e-02, -4.85817403e-01, -3.42748761e-01,\n",
       "       -6.00525320e-01, -1.90960914e-01, -7.27235973e-02, -8.45555365e-02,\n",
       "       -2.01070264e-01,  2.32740626e-01, -4.10370380e-01,  4.80220318e-02,\n",
       "       -1.08584851e-01,  9.61120352e-02, -4.59754586e-01, -4.34411913e-02,\n",
       "        3.44474018e-01, -2.60242581e-01, -1.66452631e-01, -3.80489051e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia_text = \"The European Union (EU) is a supranational political and economic union of 27 member states that are located primarily in Europe\"\n",
    "embeddings = embedder.encode(wikipedia_text)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two different texts can be compared by using different metrics. Cosine similarity (inner product) is one popular metric. Try that out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47032338"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia_text_2 = \"The EU has often been described as a sui generis political entity (without precedent or comparison) combining the characteristics of both a federation and a confederation.\"\n",
    "embeddings_2 = embedder.encode(wikipedia_text_2)\n",
    "\n",
    "# Calculate the similarity between the two embeddings\n",
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
    "\n",
    "cosine(embeddings, embeddings_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010332608"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_about_python = \"Python is an interpreted, high-level and general-purpose programming language. Python's design philosophy emphasizes code readability with its notable use of significant indentation.\"\n",
    "embeddings_python = embedder.encode(text_about_python)\n",
    "\n",
    "cosine(embeddings, embeddings_python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "Calculate the similarity of some other text samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the similary by constructing the pooling \"by hand\"\n",
    "\n",
    "This example is exactly the same as in Hugging Face model card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_embeddings(sentences, model_name):\n",
    "\n",
    "    #Mean Pooling - Take attention mask into account for correct averaging\n",
    "    def mean_pooling(model_output, attention_mask):\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "    # Load model from HuggingFace Hub\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    # Perform pooling. In this case, max pooling.\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    return sentence_embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate first the similary between the sentences by using the msmarco-distilbert-base-v4 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between wiki sentences: 0.47032377\n",
      "Similarity between wiki and python sentences: 0.010332571\n"
     ]
    }
   ],
   "source": [
    "sentence_embeddings = create_embeddings([wikipedia_text, wikipedia_text_2, text_about_python], 'sentence-transformers/msmarco-distilbert-base-v4')\n",
    "\n",
    "print(\"Similarity between wiki sentences:\", cosine(sentence_embeddings[0], sentence_embeddings[1]))\n",
    "print(\"Similarity between wiki and python sentences:\", cosine(sentence_embeddings[0], sentence_embeddings[2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the same thing with the distilbert base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between wiki sentences: 0.85148394\n",
      "Similarity between wiki and python sentences: 0.58959365\n"
     ]
    }
   ],
   "source": [
    "sentence_embeddings = create_embeddings([wikipedia_text, wikipedia_text_2, text_about_python], 'distilbert/distilbert-base-uncased')\n",
    "\n",
    "print(\"Similarity between wiki sentences:\", cosine(sentence_embeddings[0], sentence_embeddings[1]))\n",
    "print(\"Similarity between wiki and python sentences:\", cosine(sentence_embeddings[0], sentence_embeddings[2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "What do you notice about the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset for evaluating embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers.readers import InputExample\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "# Load the STS benchmark dataset\n",
    "data = load_dataset(\"mteb/stsbenchmark-sts\")\n",
    "\n",
    "test_samples = []\n",
    "for row in data[\"test\"]:\n",
    "    score = float(row[\"score\"]) / 5.0  # Normalize score to range 0 ... 1\n",
    "    inp_example = InputExample(texts=[row[\"sentence1\"], row[\"sentence2\"]], label=score)\n",
    "    test_samples.append(inp_example)\n",
    "\n",
    "train_samples = []\n",
    "for row in data[\"train\"]:\n",
    "    score = float(row[\"score\"]) / 5.0  # Normalize score to range 0 ... 1\n",
    "    inp_example = InputExample(texts=[row[\"sentence1\"], row[\"sentence2\"]], label=score)\n",
    "    train_samples.append(inp_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct our own embedding model with SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word_embedding_model = models.Transformer('distilbert/distilbert-base-uncased', max_seq_length=256)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "test_model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model accuracy (without fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6823797788593509"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name=\"sts-test\")\n",
    "test_evaluator(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7885316636814821"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_evaluator(embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune the distilbert base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<sentence_transformers.readers.InputExample.InputExample at 0x355dd3d10>,\n",
       " <sentence_transformers.readers.InputExample.InputExample at 0x355dd3dd0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A plane is taking off.', 'An air plane is taking off.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples[0].texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples[0].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6b94ce3e744a678666ceeb0c8deae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbaac342165b4c95b27c725069fcd637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import losses, evaluation\n",
    "\n",
    "n_samples = 5000\n",
    "train_dataloader = DataLoader(train_samples[:n_samples], shuffle=True, batch_size=16)\n",
    "\n",
    "train_loss = losses.CosineSimilarityLoss(test_model)\n",
    "\n",
    "evaluator = evaluation.EmbeddingSimilarityEvaluator([s.texts[0] for s in test_samples], [s.texts[1] for s in test_samples], [s.label for s in test_samples])\n",
    "\n",
    "# Tune the model\n",
    "test_model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1, warmup_steps=100, evaluator=evaluator, evaluation_steps=10, output_path=\"/Users/aappopulkkinen/repos/llm-finetuning-public/embedding_finetuning/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8108965168539495"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_evaluator(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
